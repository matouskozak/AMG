{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": -0.03855998441576958, "min_q": -0.9356681108474731, "max_q": 0.7505220174789429, "mean_td_error": -3.253392219543457}, "td_error": [0.2315060943365097, -0.40198707580566406, 0.796299397945404, 0.6574044823646545, 0.8379498720169067, -0.43879443407058716, 0.2698539197444916, -0.057636380195617676, 0.09123122692108154, -0.9139629602432251, 0.6574044823646545, 0.22368201613426208, -0.3167421519756317, 0.30074310302734375, -0.0806378722190857, -0.6108205318450928, -0.28388434648513794, -100.10978698730469, 0.32072481513023376, -0.5007188320159912, -0.022466279566287994, 0.05337369441986084, -0.1625034213066101, -0.01594782993197441, -0.9626731872558594, -0.8457081913948059, -0.46322858333587646, -0.9170961380004883, 0.03304365277290344, 0.41053152084350586, -1.2321999073028564, -0.6555021405220032], "custom_metrics": {}, "num_agent_steps_trained": 32}}, "num_env_steps_sampled": 1000, "num_env_steps_trained": 32, "num_agent_steps_sampled": 1000, "num_agent_steps_trained": 32, "last_target_update_ts": 1000, "num_target_updates": 1}, "sampler_results": {"episode_reward_max": 99.95015375664893, "episode_reward_min": 0.0, "episode_reward_mean": 85.87671152121474, "episode_len_mean": 22.093023255813954, "episode_media": {}, "episodes_this_iter": 43, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [99.75980718085107, 99.87036652260639, 99.84788480718085, 99.84406166888297, 99.81846326462765, 99.84100731382979, 99.85399351728724, 99.76801446143617, 99.87302609707447, 99.79903590425532, 99.86814328457447, 99.76899102393617, 99.8485081449468, 99.95015375664893, 0.0, 99.85199883643617, 99.7841173537234, 99.59555767952128, 99.84844581117021, 99.86795628324468, 0.0, 99.76344331781915, 99.75432180851064, 99.81906582446808, 99.52495428856383, 99.81191821808511, 99.75847739361703, 99.91636884973404, 99.86602393617021, 0.0, 0.0, 99.79932679521276, 99.77034158909575, 99.7959607712766, 99.86039311835107, 99.48884225398936, 99.82827044547872, 99.85268450797872, 99.90101396276596, 99.67854471409575, 0.0, 99.84911070478724, 0.0], "episode_lengths": [9, 15, 6, 15, 12, 26, 33, 10, 7, 18, 33, 20, 38, 41, 51, 15, 14, 26, 18, 4, 51, 3, 12, 40, 34, 1, 11, 15, 8, 51, 51, 6, 7, 4, 6, 50, 1, 42, 14, 25, 51, 5, 51]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.39826009942816, "mean_inference_ms": 2.9346109270215863, "mean_action_processing_ms": 0.07021105611002768, "mean_env_wait_ms": 16.76051385633715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 99.95015375664893, "episode_reward_min": 0.0, "episode_reward_mean": 85.87671152121474, "episode_len_mean": 22.093023255813954, "episodes_this_iter": 43, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [99.75980718085107, 99.87036652260639, 99.84788480718085, 99.84406166888297, 99.81846326462765, 99.84100731382979, 99.85399351728724, 99.76801446143617, 99.87302609707447, 99.79903590425532, 99.86814328457447, 99.76899102393617, 99.8485081449468, 99.95015375664893, 0.0, 99.85199883643617, 99.7841173537234, 99.59555767952128, 99.84844581117021, 99.86795628324468, 0.0, 99.76344331781915, 99.75432180851064, 99.81906582446808, 99.52495428856383, 99.81191821808511, 99.75847739361703, 99.91636884973404, 99.86602393617021, 0.0, 0.0, 99.79932679521276, 99.77034158909575, 99.7959607712766, 99.86039311835107, 99.48884225398936, 99.82827044547872, 99.85268450797872, 99.90101396276596, 99.67854471409575, 0.0, 99.84911070478724, 0.0], "episode_lengths": [9, 15, 6, 15, 12, 26, 33, 10, 7, 18, 33, 20, 38, 41, 51, 15, 14, 26, 18, 4, 51, 3, 12, 40, 34, 1, 11, 15, 8, 51, 51, 6, 7, 4, 6, 50, 1, 42, 14, 25, 51, 5, 51]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.39826009942816, "mean_inference_ms": 2.9346109270215863, "mean_action_processing_ms": 0.07021105611002768, "mean_env_wait_ms": 16.76051385633715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 0, "num_agent_steps_sampled": 1000, "num_agent_steps_trained": 32, "num_env_steps_sampled": 1000, "num_env_steps_trained": 32, "num_env_steps_sampled_this_iter": 1000, "num_env_steps_trained_this_iter": 32, "timesteps_total": 1000, "num_steps_trained_this_iter": 32, "agent_timesteps_total": 1000, "timers": {"training_iteration_time_ms": 175.379, "learn_time_ms": 921.063, "learn_throughput": 34.742, "synch_weights_time_ms": 0.227}, "counters": {"num_env_steps_sampled": 1000, "num_env_steps_trained": 32, "num_agent_steps_sampled": 1000, "num_agent_steps_trained": 32, "last_target_update_ts": 1000, "num_target_updates": 1}, "done": false, "episodes_total": 43, "training_iteration": 1, "trial_id": "a3c52_00000", "experiment_id": "483706a09e554be181c691845d111031", "date": "2023-02-18_14-47-45", "timestamp": 1676728065, "time_this_iter_s": 33.467294216156006, "time_total_s": 33.467294216156006, "pid": 47743, "hostname": "matous-ThinkPad-T480s", "node_ip": "192.168.0.104", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "malware-train-ember-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 0, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "malware-train-ember-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 0, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7f5f49ab1af0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf2", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7f5f49ad85b0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf2", "num_cpus_for_driver": 1}, "time_since_restore": 33.467294216156006, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 1.4812431335449219, "perf": {"cpu_util_percent": 19.15531914893617, "ram_util_percent": 94.64893617021275}}
{"custom_metrics": {}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"default_policy": {"learner_stats": {"cur_lr": 0.0005000000237487257, "mean_q": 20.733570098876953, "min_q": 7.677499294281006, "max_q": 31.714231491088867, "mean_td_error": -38.97040557861328}, "td_error": [-68.09584045410156, -68.07456970214844, -68.12019348144531, -91.25407409667969, -0.42962121963500977, 23.60710906982422, -68.07456970214844, -91.42778778076172, 23.65384292602539, 0.12185859680175781, -91.4439468383789, 0.15579891204833984, 23.60710906982422, 23.60710906982422, -91.38263702392578, -91.23115539550781, -68.13459777832031, -91.27043151855469, 0.1315746307373047, -68.13365173339844, -68.1397705078125, -91.38263702392578, -0.42962121963500977, -68.08172607421875, -68.04557800292969, 0.06348991394042969, -68.13845825195312, 0.15579891204833984, 23.60710906982422, -91.68710327148438, 23.60711097717285, 23.60711097717285], "custom_metrics": {}, "num_agent_steps_trained": 32}}, "num_env_steps_sampled": 2000, "num_env_steps_trained": 8032, "num_agent_steps_sampled": 2000, "num_agent_steps_trained": 8032, "last_target_update_ts": 2000, "num_target_updates": 3}, "sampler_results": {"episode_reward_max": 99.94576961436171, "episode_reward_min": 0.0, "episode_reward_mean": 98.11291562835241, "episode_len_mean": 8.789915966386555, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 99.83323636968085, 99.87728557180851, 99.84881981382979, 99.75762549867021, 99.85546875, 99.73805269281915, 99.55844830452128, 99.90261386303192, 99.83849318484043, 99.7811876662234, 99.8515625, 99.83624916888297, 99.87142619680851, 99.87223653590425, 99.75386469414893, 99.90635388962765, 99.70698969414893, 99.86051778590425, 99.75413480718085, 99.69834607712765, 99.67179188829788, 99.82421875, 99.79411153590425, 99.77699052526596, 99.80855219414893, 99.86849650930851, 99.88056848404256, 99.94576961436171, 99.79024684175532, 99.84688746675532, 99.79822556515957, 99.80254737367021, 99.78089677526596, 99.89426113696808, 99.86515126329788, 99.82845744680851, 99.30011635638297, 99.77320894281915, 99.72296791888297, 99.87693234707447, 99.75729305186171, 99.81006898271276, 99.85210272606383, 99.79425698138297, 99.83724650930851, 99.75654504654256, 99.80410571808511, 99.73776180186171, 99.80406416223404, 99.93326130319149, 99.83433759973404, 99.86693816489361, 99.82987034574468, 99.80427194148936, 99.79494265292553, 99.77682430186171, 99.90936668882979, 99.64112367021276, 99.83361037234043, 99.83568816489361, 99.83286236702128, 99.87942569813829, 99.8916638962766, 99.77622174202128, 99.8231798537234, 99.77896442819149, 99.64272357047872, 99.90834857047872, 99.78879238696808, 99.72452626329788, 99.66023936170212, 99.79814245345744, 99.76523021941489, 99.83005734707447, 99.83932430186171, 99.76824301861703, 99.71951878324468, 99.61924451462765, 99.81825548537235, 99.79789311835107, 99.83926196808511, 99.63570063164893, 99.72722739361703, 99.68752077792553, 99.82455119680851, 99.77345827792553, 99.91042636303192, 99.80923786569149, 99.84721991356383, 99.86286569148936, 99.82650432180851, 99.75623337765957, 99.60960355718085, 99.82615109707447, 99.80121758643617, 99.83280003324468, 99.80404338430851, 99.88597074468085, 99.81775681515957, 99.76830535239361, 99.80591339760639, 99.83442071143617, 99.79463098404256, 99.79525432180851, 99.86824717420212, 99.63530585106383, 99.84246176861703, 99.74601063829788, 99.78777426861703, 99.4531873337766, 99.81617769281915, 99.83861785239361, 99.57380319148936, 99.80803274601064, 99.55398105053192, 99.87032496675532, 99.73690990691489], "episode_lengths": [51, 51, 4, 4, 11, 22, 1, 10, 10, 12, 9, 14, 23, 9, 14, 3, 7, 12, 13, 7, 8, 11, 18, 14, 1, 5, 1, 15, 1, 5, 23, 1, 10, 7, 7, 4, 4, 12, 38, 6, 17, 1, 6, 5, 4, 17, 7, 15, 2, 4, 3, 10, 7, 16, 1, 5, 7, 7, 8, 6, 16, 5, 8, 4, 4, 3, 4, 4, 2, 6, 4, 4, 6, 10, 8, 3, 7, 5, 13, 5, 7, 6, 14, 16, 6, 10, 4, 4, 5, 5, 12, 15, 2, 9, 3, 6, 2, 1, 9, 4, 3, 6, 4, 2, 1, 20, 6, 35, 3, 5, 4, 7, 2, 9, 6, 9, 24, 4, 9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 24.852686200006087, "mean_inference_ms": 3.1172732363219033, "mean_action_processing_ms": 0.07485485505843273, "mean_env_wait_ms": 18.351230187632932, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 99.94576961436171, "episode_reward_min": 0.0, "episode_reward_mean": 98.11291562835241, "episode_len_mean": 8.789915966386555, "episodes_this_iter": 119, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 99.83323636968085, 99.87728557180851, 99.84881981382979, 99.75762549867021, 99.85546875, 99.73805269281915, 99.55844830452128, 99.90261386303192, 99.83849318484043, 99.7811876662234, 99.8515625, 99.83624916888297, 99.87142619680851, 99.87223653590425, 99.75386469414893, 99.90635388962765, 99.70698969414893, 99.86051778590425, 99.75413480718085, 99.69834607712765, 99.67179188829788, 99.82421875, 99.79411153590425, 99.77699052526596, 99.80855219414893, 99.86849650930851, 99.88056848404256, 99.94576961436171, 99.79024684175532, 99.84688746675532, 99.79822556515957, 99.80254737367021, 99.78089677526596, 99.89426113696808, 99.86515126329788, 99.82845744680851, 99.30011635638297, 99.77320894281915, 99.72296791888297, 99.87693234707447, 99.75729305186171, 99.81006898271276, 99.85210272606383, 99.79425698138297, 99.83724650930851, 99.75654504654256, 99.80410571808511, 99.73776180186171, 99.80406416223404, 99.93326130319149, 99.83433759973404, 99.86693816489361, 99.82987034574468, 99.80427194148936, 99.79494265292553, 99.77682430186171, 99.90936668882979, 99.64112367021276, 99.83361037234043, 99.83568816489361, 99.83286236702128, 99.87942569813829, 99.8916638962766, 99.77622174202128, 99.8231798537234, 99.77896442819149, 99.64272357047872, 99.90834857047872, 99.78879238696808, 99.72452626329788, 99.66023936170212, 99.79814245345744, 99.76523021941489, 99.83005734707447, 99.83932430186171, 99.76824301861703, 99.71951878324468, 99.61924451462765, 99.81825548537235, 99.79789311835107, 99.83926196808511, 99.63570063164893, 99.72722739361703, 99.68752077792553, 99.82455119680851, 99.77345827792553, 99.91042636303192, 99.80923786569149, 99.84721991356383, 99.86286569148936, 99.82650432180851, 99.75623337765957, 99.60960355718085, 99.82615109707447, 99.80121758643617, 99.83280003324468, 99.80404338430851, 99.88597074468085, 99.81775681515957, 99.76830535239361, 99.80591339760639, 99.83442071143617, 99.79463098404256, 99.79525432180851, 99.86824717420212, 99.63530585106383, 99.84246176861703, 99.74601063829788, 99.78777426861703, 99.4531873337766, 99.81617769281915, 99.83861785239361, 99.57380319148936, 99.80803274601064, 99.55398105053192, 99.87032496675532, 99.73690990691489], "episode_lengths": [51, 51, 4, 4, 11, 22, 1, 10, 10, 12, 9, 14, 23, 9, 14, 3, 7, 12, 13, 7, 8, 11, 18, 14, 1, 5, 1, 15, 1, 5, 23, 1, 10, 7, 7, 4, 4, 12, 38, 6, 17, 1, 6, 5, 4, 17, 7, 15, 2, 4, 3, 10, 7, 16, 1, 5, 7, 7, 8, 6, 16, 5, 8, 4, 4, 3, 4, 4, 2, 6, 4, 4, 6, 10, 8, 3, 7, 5, 13, 5, 7, 6, 14, 16, 6, 10, 4, 4, 5, 5, 12, 15, 2, 9, 3, 6, 2, 1, 9, 4, 3, 6, 4, 2, 1, 20, 6, 35, 3, 5, 4, 7, 2, 9, 6, 9, 24, 4, 9]}, "sampler_perf": {"mean_raw_obs_processing_ms": 24.852686200006087, "mean_inference_ms": 3.1172732363219033, "mean_action_processing_ms": 0.07485485505843273, "mean_env_wait_ms": 18.351230187632932, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 0, "num_agent_steps_sampled": 2000, "num_agent_steps_trained": 8032, "num_env_steps_sampled": 2000, "num_env_steps_trained": 8032, "num_env_steps_sampled_this_iter": 1000, "num_env_steps_trained_this_iter": 8000, "timesteps_total": 2000, "num_steps_trained_this_iter": 8000, "agent_timesteps_total": 2000, "timers": {"training_iteration_time_ms": 283.725, "learn_time_ms": 22.57, "learn_throughput": 1417.788, "synch_weights_time_ms": 0.495}, "counters": {"num_env_steps_sampled": 2000, "num_env_steps_trained": 8032, "num_agent_steps_sampled": 2000, "num_agent_steps_trained": 8032, "last_target_update_ts": 2000, "num_target_updates": 3}, "done": false, "episodes_total": 162, "training_iteration": 2, "trial_id": "a3c52_00000", "experiment_id": "483706a09e554be181c691845d111031", "date": "2023-02-18_14-48-53", "timestamp": 1676728133, "time_this_iter_s": 68.62915277481079, "time_total_s": 102.0964469909668, "pid": 47743, "hostname": "matous-ThinkPad-T480s", "node_ip": "192.168.0.104", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "malware-train-ember-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 0, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "malware-train-ember-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 0, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0005, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7f5f49a034c0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf2", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "target_network_update_freq": 500, "replay_buffer_config": {"type": "<class 'ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer'>", "prioritized_replay": -1, "capacity": 50000, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "replay_sequence_length": 1, "worker_side_prioritization": false, "replay_mode": "independent"}, "store_buffer_in_checkpoints": false, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "before_learn_on_batch": null, "training_intensity": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7f5f49a39220>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "tf2", "num_cpus_for_driver": 1}, "time_since_restore": 102.0964469909668, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 1.4812431335449219, "perf": {"cpu_util_percent": 25.97216494845361, "ram_util_percent": 97.12577319587629}}
